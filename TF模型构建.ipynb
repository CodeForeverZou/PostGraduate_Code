{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF模型构建.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeForeverZou/PostGraduate_Code/blob/master/TF%E6%A8%A1%E5%9E%8B%E6%9E%84%E5%BB%BA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWyOQ6Ky3xkh",
        "colab_type": "text"
      },
      "source": [
        "# 装载Google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cMzSKvejY7z",
        "colab_type": "code",
        "outputId": "367e1fa2-d0b3-4fb0-d9ec-607dcd38211f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va71czDyjnaN",
        "colab_type": "code",
        "outputId": "cee9ff91-9c75-4cf1-e630-8bc4f180b0e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/\")\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Colab Notebooks\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0OJ0FqE4j00",
        "colab_type": "text"
      },
      "source": [
        "# 加载数据"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJa-dZj7xB47",
        "colab_type": "text"
      },
      "source": [
        "## 由keras加载MNSIT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Q2Tbu2Fj47u",
        "colab_type": "code",
        "outputId": "1a172d7b-87b7-428b-c5dc-ef6b47ccffc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "#import tensorflow.keras.layers\n",
        "(mnist_images, mnist_labels), (X_test,Y_test) = tf.keras.datasets.mnist.load_data()\n",
        "Y_test\n",
        "#(Xf_train,Yf_train),(Xf_test,Yf_test)=tf.keras.datasets.fashion_mnist.load_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "c9dfd567-add3-4e0e-a390-faabd30192aa",
        "id": "Yj-tmaCb1GlE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#len(mnist_images)\n",
        "from keras.utils import np_utils\n",
        "#dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    #(tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32),.cast(mnist_labels,tf.int64)))\n",
        "X_test=X_test.reshape(10000,784).astype('float32')\n",
        "X_test /= 255\n",
        "y_test = np_utils.to_categorical(Y_test,10)\n",
        "X_test.shape[0]\n",
        "y_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igE76UoT6mTc",
        "colab_type": "code",
        "outputId": "986fe1d4-ef3f-4e4b-be41-c85ec03621de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "#y_test = np_utils.to_categorical(Y_test,10)\n",
        "y_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzTgjnIMw2d2",
        "colab_type": "text"
      },
      "source": [
        "## 由TF加载MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7QbzcjdnMpU",
        "colab_type": "code",
        "outputId": "1cf48887-4f65-4115-dd5d-3d20d401816b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist=input_data.read_data_sets(\"MNIST_data/\",one_hot=True)\n",
        "x_train=mnist.train.images\n",
        "x_test=mnist.test.images\n",
        "x_test /=255.0\n",
        "y_train=mnist.train.labels\n",
        "y_test=mnist.test.labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-3-a2bda8563014>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjVTHZZbuadU",
        "colab_type": "code",
        "outputId": "37503be2-ea19-4eaa-8dd5-ade9f94ff730",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(y_train)\n",
        "x_test.shape\n",
        "y_test.shape\n",
        "#len(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEJ1bzW6rpGU",
        "colab_type": "code",
        "outputId": "f9df4506-bbdc-4b62-814d-362ab96e39f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "#from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.subplot(1,2,1)  #(row,col,index)\n",
        "plt.imshow(np.reshape(x_train[0],[28,28]),cmap='Greys_r')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(np.reshape(x_train[1],[28,28]))\n",
        "y_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAC4CAYAAAD61bdSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAImigQNAomjgAJAoGjgAJIoGDgCJ+n88kLpj6lQODgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juYxc_w1yHwx",
        "colab_type": "text"
      },
      "source": [
        "## 由sklearn加载MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G848u1XWxVmh",
        "colab_type": "code",
        "outputId": "82989c6d-fdae-4ca1-a878-826fae3d8bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from sklearn.datasets import fetch_mldata\n",
        "mnist2=fetch_mldata(\"MNIST original\")\n",
        "X,Y=mnist2[\"data\"],mnist2[\"target\"]\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:85: DeprecationWarning: Function fetch_mldata is deprecated; fetch_mldata was deprecated in version 0.20 and will be removed in version 0.22. Please use fetch_openml.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:85: DeprecationWarning: Function mldata_filename is deprecated; mldata_filename was deprecated in version 0.20 and will be removed in version 0.22. Please use fetch_openml.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(70000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grJQU7Ek4fjI",
        "colab_type": "text"
      },
      "source": [
        "# 定义模型\n",
        "**问题：**\n",
        "\n",
        "- Y_test为什么是[10000]，对于序列方式\n",
        "\n",
        "- y_test为什么是[10000,10]，对于函数、子类化\n",
        "\n",
        "**注意：**\n",
        "\n",
        "keras.layers系列都有activation参数（可传'relu'，也可tf.nn.relu）\n",
        "\n",
        "这与TensorFlow1.0中只能tf.nn.relu不同"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WHk5-MU4pq9",
        "colab_type": "text"
      },
      "source": [
        "## 序列方式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjGi_N4f4uV2",
        "colab_type": "code",
        "outputId": "3e8ba63b-8ec2-49f1-e3e8-11e04ca4fc35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import numpy as np\n",
        "keras_model=tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "  #tf.keras.layers.Dense(32,input_shape=(784,)),\n",
        "  #tf.keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "#keras_model(X_test[0])\n",
        "keras_model.compile(optimizer='adam',\n",
        "          loss='sparse_categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "#keras_model.fit(X_test,Y_test,epochs=3)\n",
        "yy=[ np.argmax(i) for i in mnist.test.labels]\n",
        "keras_model.fit(mnist.test.images,np.array(yy),epochs=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 1s 66us/sample - loss: 2.1079 - acc: 0.4593\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 1s 61us/sample - loss: 1.4285 - acc: 0.6938\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 1s 60us/sample - loss: 0.9863 - acc: 0.7884\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f86b695a828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3ww_BLb7HyA",
        "colab_type": "text"
      },
      "source": [
        "## 函数方式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6zCV9YZ7eHl",
        "colab_type": "code",
        "outputId": "66bbe4e9-1bef-4a04-9ff7-4b948d6c861f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "tf_keras_model=tf.keras.Sequential()\n",
        "tf_keras_model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "tf_keras_model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "tf_keras_model.compile(optimizer='adam',loss='categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "tf_keras_model.fit(X_test,y_test,epochs=3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples\n",
            "Epoch 1/3\n",
            "10000/10000 [==============================] - 1s 65us/sample - loss: 0.5099 - acc: 0.8572\n",
            "Epoch 2/3\n",
            "10000/10000 [==============================] - 1s 61us/sample - loss: 0.2263 - acc: 0.9348\n",
            "Epoch 3/3\n",
            "10000/10000 [==============================] - 1s 59us/sample - loss: 0.1637 - acc: 0.9509\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f872d405e10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE4mqXZv9rKW",
        "colab_type": "text"
      },
      "source": [
        "## 子类化方式\n",
        "- 使用 tf.keras.datasets 获得数据集并预处理\n",
        "\n",
        "- 使用 tf.keras.Model 和 tf.keras.layers 构建模型\n",
        "\n",
        "- 构建模型训练流程，使用 tf.keras.losses 计算损失函数，并使用 tf.keras.optimizer 优化模型\n",
        "\n",
        "- 构建模型评估流程，使用 tf.keras.metrics 计算评估指标\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynqpINK2R3ln",
        "colab_type": "text"
      },
      "source": [
        "### 简单模式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmbFfZPk9qNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.dense1=tf.keras.layers.Dense(128,activation='relu')\n",
        "    self.dense2=tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "\n",
        "  def call(self,inputs):\n",
        "    x=self.dense1(inputs)\n",
        "    #x=tf.keras\n",
        "    return tf.reshape(self.dense2(x),[100000,-1])\n",
        "\n",
        "myModel=MyModel()\n",
        "#———————通常的训练、预测———————\n",
        "\n",
        "myModel.compile(optimizer='adam',loss='categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "myModel.fit(X_test,y_test,epochs=3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWaEw2r8R8KF",
        "colab_type": "text"
      },
      "source": [
        "### 即时运行（Eager Execution）模式"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWwCT6eFSMoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.dense1=tf.keras.layers.Dense(128,activation='relu')\n",
        "    self.dense2=tf.keras.layers.Dense(10,activation=tf.nn.softmax)\n",
        "\n",
        "  def call(self,inputs):\n",
        "    x=self.dense1(inputs)\n",
        "    #x=tf.keras\n",
        "    return tf.reshape(self.dense2(x),[100000,-1])\n",
        "\n",
        "myModel=MyModel()\n",
        "\n",
        "#———————Eager Execution（即时运行）模式———————\n",
        "optimizer=tf.keras.optimizers.SGD(0.01)\n",
        "for i in range(3):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred=myModel(mnist.test.images)\n",
        "    #loss=tf.reduce_mean(tf.square(y_pred-y))\n",
        "    #原始的\n",
        "    #loss=tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(labels=y_test ,logits=y_pred))\n",
        "    #新的\n",
        "    loss = tf.keras.losses.categorical_crossentropy(y_true=y_test ,y_pred=y_pred)\n",
        "    #loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=mnist.test.labels, y_pred=y_pred)\n",
        "  grads=tape.gradient(loss,myModel.variables) # 使用 model.variables 这一属性直接获得模型中的所有变量\n",
        "  optimizer.apply_gradients(grads_and_vars=zip(grads,myModel.variables))\n",
        "\n",
        "#print(myModel.variables)\n",
        "#pre_correct=tf.equal(y_pred,y_test)\n",
        "#acc=tf.reduce_mean(tf.cast(pre_correct,tf.float32))\n",
        "#print(mnist.test.images[1].shape)\n",
        "c_accuracy = tf.keras.metrics.CategoricalAccuracy()\n",
        "y_pred = myModel.predict(X_test)\n",
        "c_accuracy.update_state(y_true=y_test, y_pred=y_pred)\n",
        "print(\"acc:%f\"%c_accuracy.result())\n",
        "\n",
        "'''\n",
        "for i in range(3):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred=myModel(mnist.test.images)\n",
        "    loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=mnist.test.labels, y_pred=y_pred)\n",
        "  grads=tape.gradient(loss,myModel.variables) \n",
        "  optimizer.apply_gradients(grads_and_vars=zip(grads,myModel.variables))\n",
        "sparse_categorical_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "y_pred = myModel.predict(mnist.test.images[:])\n",
        "sparse_categorical_accuracy.update_state(y_true=mnist.test.labels, y_pred=y_pred)\n",
        "print(\"acc:%f\"%sparse_categorical_accuracy.result())\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFzJ8TkYvJwh",
        "colab_type": "code",
        "outputId": "3a1ab474-850e-46c3-cd14-5e32ed1b6595",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "y_true = (0, 0, 1, 0)\n",
        "y_pred = (0.02, 0.05, 0.83, 0.1)\n",
        "acc = tf.keras.metrics.categorical_accuracy(y_true, y_pred)\n",
        "print(acc)\n",
        "y_true = 2\n",
        "y_pred = (0.02, 0.05, 0.83, 0.1)\n",
        "#acc = tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
        "print(acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Cast_56:0\", shape=(), dtype=float32)\n",
            "Tensor(\"Cast_56:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjR989KYRsRR",
        "colab_type": "text"
      },
      "source": [
        "### 自定义层、损失、评估函数\n",
        "- 自定义层需要继承 tf.keras.layers.Layer 类，并重写 __init __ 、 build 和 call 三个方法\n",
        "- 自定义损失函数需要继承 tf.keras.losses.Loss 类，重写 call 方法即可\n",
        "- 自定义评估指标需要继承 tf.keras.metrics.Metric 类，并重写 __init_ _ 、 update_state 和 result 三个方法\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiCI6_4jRzpu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#—————————自定义全连接层——————————\n",
        "class LinearLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super().__init__()\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):  # 这里 input_shape 是第一次运行call()时参数inputs的形状\n",
        "        self.w = self.add_variable(name='w',\n",
        "            shape=[input_shape[-1], self.units], initializer=tf.zeros_initializer())\n",
        "        self.b = self.add_variable(name='b',\n",
        "            shape=[self.units], initializer=tf.zeros_initializer())\n",
        "\n",
        "    def call(self, inputs):\n",
        "        y_pred = tf.matmul(inputs, self.w) + self.b\n",
        "        return y_pred\n",
        "\n",
        "class LinearModel(tf.keras.Model): # 模型中调用\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer = LinearLayer(units=1)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = self.layer(inputs)\n",
        "        return output\n",
        "    \n",
        "#—————————自定义损失函数——————————\n",
        "class MeanSquaredError(tf.keras.losses.Loss): # 主要参数 y_true, y_pred\n",
        "    def call(self, y_true, y_pred):\n",
        "        return tf.reduce_mean(tf.square(y_pred - y_true))\n",
        "\n",
        "#—————————自定义评估指标——————————\n",
        "class SparseCategoricalAccuracy(tf.keras.metrics.Metric):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.total = self.add_weight(name='total', dtype=tf.int32, initializer=tf.zeros_initializer())\n",
        "        self.count = self.add_weight(name='count', dtype=tf.int32, initializer=tf.zeros_initializer())\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None): # 主要参数 y_true, y_pred\n",
        "        values = tf.cast(tf.equal(y_true, tf.argmax(y_pred, axis=-1, output_type=tf.int32)), tf.int32)\n",
        "        self.total.assign_add(tf.shape(y_true)[0])\n",
        "        self.count.assign_add(tf.reduce_sum(values))\n",
        "\n",
        "    def result(self):\n",
        "        return self.count / self.total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4JFz38CIgRA",
        "colab_type": "text"
      },
      "source": [
        "## Tensorflow1.0 建立模型\n",
        "过程：\n",
        "\n",
        "1、模型建立\n",
        "- 建立layer函数\n",
        "- 建立变量（输入）\n",
        "\n",
        "2、训练定义\n",
        "- 损失函数 loss\n",
        "- 优化器 optimizer\n",
        "- 评估函数\n",
        "\n",
        "3、进行训练\n",
        "- 训练周期 epoch、批次数 batch\n",
        "- loss , acc = sess.run(loss , feed_dict)\n",
        "\n",
        "4、进行预测\n",
        "- predict = sess.run (y , feed_dict)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xm8Yi-dIrvH",
        "colab_type": "code",
        "outputId": "83fe18db-339c-4782-b5da-8d3f7f9900ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "#构建模型\n",
        "W=tf.Variable(tf.random_normal([784,10]))\n",
        "b=tf.Variable(tf.random_normal([10]))\n",
        "x = tf.placeholder(\"float\", [None, 784])\n",
        "y_predict=tf.matmul(x,W)+b\n",
        "#定义训练目标\n",
        "y = tf.placeholder(\"float\", [None, 10])\n",
        "loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_predict,labels=y))\n",
        "optimizer=tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
        "pre_correct=tf.equal(tf.argmax(y,1),\n",
        "          tf.argmax(y_predict,1))\n",
        "acc=tf.reduce_mean(tf.cast(pre_correct,tf.float32))\n",
        "#进行训练\n",
        "sess=tf.Session()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "for epoch in range(15):\n",
        "  for batch in range(550):\n",
        "    batch_x,batch_y=mnist.train.next_batch(100)\n",
        "    sess.run(optimizer,feed_dict={x:batch_x,y:batch_y})\n",
        "  loss_r,acc_r=sess.run([loss,acc],feed_dict={x:batch_x,y:batch_y})\n",
        "  print(\"Train Epoch:{},loss{:.4f},acc{:3f}\".format(epoch+1,loss_r,acc_r))\n",
        "#进行预测\n",
        "x_test,y_test=mnist.test.images,mnist.test.labels\n",
        "test_acc=sess.run(acc,feed_dict={x:x_test,y:y_test})\n",
        "print(\"test_acc:\",test_acc)\n",
        "\n",
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch:1,loss2.4954,acc0.610000\n",
            "Train Epoch:2,loss1.2900,acc0.740000\n",
            "Train Epoch:3,loss0.6365,acc0.820000\n",
            "Train Epoch:4,loss0.6393,acc0.850000\n",
            "Train Epoch:5,loss0.6617,acc0.840000\n",
            "Train Epoch:6,loss1.0306,acc0.780000\n",
            "Train Epoch:7,loss0.3748,acc0.920000\n",
            "Train Epoch:8,loss0.7530,acc0.860000\n",
            "Train Epoch:9,loss0.4494,acc0.880000\n",
            "Train Epoch:10,loss0.5840,acc0.850000\n",
            "Train Epoch:11,loss0.2019,acc0.910000\n",
            "Train Epoch:12,loss0.4331,acc0.880000\n",
            "Train Epoch:13,loss0.3012,acc0.920000\n",
            "Train Epoch:14,loss0.4124,acc0.920000\n",
            "Train Epoch:15,loss0.5264,acc0.930000\n",
            "test_acc: 0.0892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhf8sjKnAgCg",
        "colab_type": "text"
      },
      "source": [
        "# 自动求导、反向传播"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt4r3gFponTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "#房价线性回归\n",
        "x=np.arange(1,6,1).astype(np.float32)\n",
        "y=x*2+1\n",
        "#type(y[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APf39SNsldp5",
        "colab_type": "text"
      },
      "source": [
        "## numpy实现"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkxp5M2IfRxv",
        "colab_type": "code",
        "outputId": "04b5cbca-0c74-4417-94c3-178091fbc8ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "a,b=0,0\n",
        "for e in range(10):\n",
        "  y_pred=x*a+b\n",
        "  grad_a,grad_b=(y_pred-y).dot(x),(y_pred-y).sum()\n",
        "  #print(grad_a,grad_b)\n",
        "  a,b=a-0.01*grad_a,b-0.01*grad_b\n",
        "print(a,b)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1051298189163203 0.6193855237960816\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Msg_r7ZlhB_",
        "colab_type": "text"
      },
      "source": [
        "## GradientTape实现"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0NyMkd1lplt",
        "colab_type": "code",
        "outputId": "1692b71b-0e27-47b0-9e2a-de32c68fab2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "#tf.enable_eager_execution()\n",
        "x = tf.constant(x)\n",
        "y = tf.constant(y)\n",
        "a=tf.Variable(0.)\n",
        "b=tf.Variable(0.)\n",
        "# 0.1将梯度爆炸、或消失nan\n",
        "optimizer=tf.keras.optimizers.SGD(0.01)\n",
        "variables = [a, b]\n",
        "for e in range(10):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred=a*x+b\n",
        "    loss=0.5*tf.reduce_sum(tf.square(y_pred-y))\n",
        "  grads=tape.gradient(loss,variables)\n",
        "  optimizer.apply_gradients(zip(grads,variables))\n",
        "print(a,b)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-17414574.0> <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=-4823557.5>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgpZqV7sfTvr",
        "colab_type": "text"
      },
      "source": [
        "# 其他"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1e696176-9771-4c7c-8469-fb799762e8de",
        "id": "Zf5pvX27uOIt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "X_raw = np.array([2013, 2014, 2015, 2016, 2017], dtype=np.float32)\n",
        "y_raw = np.array([12000, 14000, 15000, 16500, 17500], dtype=np.float32)\n",
        "\n",
        "X = (X_raw - X_raw.min()) / (X_raw.max() - X_raw.min())\n",
        "y = (y_raw - y_raw.min()) / (y_raw.max() - y_raw.min())\n",
        "\n",
        "X = tf.constant(X)\n",
        "y = tf.constant(y)\n",
        "\n",
        "a = tf.Variable(initial_value=0.)\n",
        "b = tf.Variable(initial_value=0.)\n",
        "variables = [a, b]\n",
        "\n",
        "num_epoch = 10000\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
        "for e in range(num_epoch):\n",
        "    # 使用tf.GradientTape()记录损失函数的梯度信息\n",
        "    with tf.GradientTape() as tape:\n",
        "        y_pred = a * X + b\n",
        "        loss = 0.5 * tf.reduce_sum(tf.square(y_pred - y))\n",
        "    # TensorFlow自动计算损失函数关于自变量（模型参数）的梯度\n",
        "    grads = tape.gradient(loss, variables)\n",
        "    # TensorFlow自动根据梯度更新参数\n",
        "    optimizer.apply_gradients(grads_and_vars=zip(grads, variables))\n",
        "\n",
        "print(a, b)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.97637> <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.057565063>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f11WwYaD5I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "fashion_mnist=tf.keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "#train_images = tf.reshape(train_images,(60000,784))\n",
        "train_images = train_images.reshape(60000,784).astype('float32')\n",
        "#tf.cast(train_images, tf.float32)\n",
        "train_labels.astype('float32')\n",
        "\n",
        "\n",
        "net=tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Dense(120),\n",
        "      tf.keras.layers.Dense(10)                                \n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.9, momentum=0.0, nesterov=False)\n",
        "\n",
        "net.compile(optimizer=optimizer,\n",
        "          loss='sparse_categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "#train_images = train_images.batch(1000)\n",
        "net.fit(train_images, train_labels, epochs=5,steps_per_epoch=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic-xtvWwWVvr",
        "colab_type": "code",
        "outputId": "d6bb9696-1db7-465a-8dc3-dbaa5b12ad64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "import tensorflow as tf  # 深度学习库，Tensor 就是多维数组\n",
        "\n",
        "mnist = tf.keras.datasets.mnist  # mnist 是 28x28 的手写数字图片和对应标签的数据集\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()  # 分割数据集\n",
        "\n",
        "#x_train = tf.keras.utils.normalize(x_train, axis=1)  # 把数据值缩放到 0 到 1\n",
        "#x_test = tf.keras.utils.normalize(x_test, axis=1)  \n",
        "x_train=x_train.reshape(60000,784).astype('float32')\n",
        "x_train /= 255\n",
        "\n",
        "net=tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Dense(120),\n",
        "      tf.keras.layers.Dense(10)                                \n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.9, momentum=0.0, nesterov=False)\n",
        "\n",
        "net.compile(optimizer=optimizer,\n",
        "          loss='sparse_categorical_crossentropy',\n",
        "          metrics=['accuracy'])\n",
        "#train_images = train_images.batch(1000)\n",
        "net.fit(x_train, y_train, epochs=3)\n",
        "'''\n",
        "model = tf.keras.models.Sequential()  # 基础的前馈神经网络模型\n",
        "model.add(tf.keras.layers.Flatten())  # 把图片展平成 1x784\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # 简单的全连接图层,，128 个单元，激活函数为 relu\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu)) \n",
        "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))  # 输出层 ，10 个单元， 使用 Softmax 获得概率分布\n",
        "\n",
        "model.compile(optimizer='adam',  # 默认的较好的优化器\n",
        "              loss='sparse_categorical_crossentropy',  # 评估“错误”的损失函数，模型应该尽量降低损失\n",
        "              metrics=['accuracy'])  # 评价指标\n",
        "\n",
        "model.fit(x_train, y_train, epochs=3)  # 训练模型\n",
        "'''\n",
        "#val_loss, val_acc = model.evaluate(x_test, y_test)  # 评估模型对样本数据的输出结果\n",
        "#print(val_loss)  # 模型的损失值\n",
        "#print(val_acc)  # 模型的准确度"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples\n",
            "Epoch 1/3\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 2.3094 - acc: 0.0987\n",
            "Epoch 2/3\n",
            "60000/60000 [==============================] - 5s 78us/sample - loss: 2.3026 - acc: 0.0986\n",
            "Epoch 3/3\n",
            "60000/60000 [==============================] - 5s 77us/sample - loss: 2.3026 - acc: 0.0986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nmodel = tf.keras.models.Sequential()  # 基础的前馈神经网络模型\\nmodel.add(tf.keras.layers.Flatten())  # 把图片展平成 1x784\\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # 简单的全连接图层,，128 个单元，激活函数为 relu\\nmodel.add(tf.keras.layers.Dense(128, activation=tf.nn.relu)) \\nmodel.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))  # 输出层 ，10 个单元， 使用 Softmax 获得概率分布\\n\\nmodel.compile(optimizer='adam',  # 默认的较好的优化器\\n              loss='sparse_categorical_crossentropy',  # 评估“错误”的损失函数，模型应该尽量降低损失\\n              metrics=['accuracy'])  # 评价指标\\n\\nmodel.fit(x_train, y_train, epochs=3)  # 训练模型\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}